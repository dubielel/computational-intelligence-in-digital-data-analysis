{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Laboratorium 6 – Środowisko wieloagentowe\n",
    "\n",
    "## Autorzy\n",
    "- Kacper Cienkosz\n",
    "- Miłosz Dubiel"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f917625b4063b4e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Wstęp teoretyczny\n",
    "\n",
    "## Algorytm PPO\n",
    "Proximal Policy Optimization (PPO) jest nowoczesnym algorytmem używanym do trenowania polityk (policy) w modelach, które podejmują decyzje sekwencyjne, np. w grach czy robotyce. PPO operuje na polityce, która określa prawdopodobieństwo wyboru akcji w danym stanie. Polityka jest aktualizowana w iteracyjny sposób, aby maksymalizować oczekiwaną sumę nagród.\n",
    "\n",
    "### Kroki Algorytmu:\n",
    "* Zbieranie Danych: Na początku algorytmu agent działa w środowisku przez pewien czas, zbierając dane na temat stanów, akcji, nagród oraz nowych stanów.\n",
    "* Obliczanie Wartości Docelowych: Obliczane są wartości docelowe oraz przewidywania wartości dla stanów. Pomaga to w ocenie, jak dobre są akcje podejmowane przez agenta.\n",
    "* Użycie Surrogate Objective: PPO wprowadza funkcję celu (surrogate objective), która mierzy, jak bardzo nowa polityka różni się od starej, a jednocześnie promuje zmiany, które przynoszą większe nagrody.\n",
    "* Aktualizacja Polityki: Polityka jest aktualizowana, aby maksymalizować wartość surrogate objective, przy czym ogranicza się, jak bardzo polityka może się zmieniać w jednej iteracji (tzw. klipping, czyli ograniczenie gradientu).\n",
    "\n",
    "### Zalety PPO\n",
    "* Stabilność\n",
    "* Prostota Implementacji\n",
    "* Efektywność\n",
    "\n",
    "## Środowisko FlagCapture\n",
    "Środowisko FlagCapture jest przez autorów gymnasium określane jako \"walka pamięci i informacji\". Gra opiera się na znalezieniu ukrytej w siatce 9 x 7 flagi. Dwóch agentów porusza się po tej siatce i odkrywa pola, na których aktualnie się znajdują. Jako odpowiedź mogą dostać podpowiedź odnośnie kierunku, w którym powinni się kierować, żeby zdobyć flagę lub mogą natrafić na bombę, która przeniesie danego agenta do punktu początkowego.\n",
    "\n",
    "## Rozważane hiperparametry\n",
    "Z naszych eksperymentów wynikło, że na poprawny wynik uczenia mocno wpływa długość epizodu (oznaczona przez nas jako `max_cycles`). Jednakże, ze względu na niewystarczającą moc obliczeniową, nie byliśmy w stanie przeprowadzić procesu uczenia dla bardzo dużych wartości `max_cycles`. Spowodowało to też dosyć niską liczbę epizodów treningowych. Ponadto, ustawiliśmy współczynnik entropii na 0.01 oraz współczynnik funkcji wartości na 0.5.\n",
    "\n",
    "## Wpływ hiperparametrów na uczenie w naszym przypadku\n",
    "Tak jak napomknęliśmy powyżej: dobrym krokiem dla FlagCapture jest zwiększenie liczby kroków w pojedynczym epizodzie. Do dalszych eksperymentów w tym zakresie ogranicza nas moc obliczeniowa.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c83b63ce41b7df2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from supersuit import color_reduction_v0, frame_stack_v1, resize_v1\n",
    "\n",
    "from pettingzoo.atari import flag_capture_v2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T20:41:35.918784Z",
     "start_time": "2024-06-09T20:41:35.914315Z"
    }
   },
   "id": "daaead822e7ab994",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Klasa opakowująca parametry"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f446c7bf1957c4b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class AlgoParams:\n",
    "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ent_coef: float = 0.1\n",
    "    vf_coef: float = 0.1\n",
    "    clip_coef: float = 0.1\n",
    "    gamma: float = 0.99\n",
    "    lambd: float = 0.9\n",
    "    batch_size: int = 32\n",
    "    stack_size: int = 4\n",
    "    frame_size: tuple = (64, 64)\n",
    "    max_cycles: int = 125\n",
    "    total_episodes: int = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T20:41:37.955831Z",
     "start_time": "2024-06-09T20:41:37.950811Z"
    }
   },
   "id": "21353ff663d66b93",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementacja Agenta z konwolucyjną siecią neuronową"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee4195cab278d072"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Agent(nn.Module):\n",
    "    def __init__(self, num_actions):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            self._layer_init(nn.Conv2d(4, 32, 3, padding=1)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            self._layer_init(nn.Conv2d(32, 64, 3, padding=1)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            self._layer_init(nn.Conv2d(64, 128, 3, padding=1)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            self._layer_init(nn.Linear(128 * 8 * 8, 512)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.actor = self._layer_init(nn.Linear(512, num_actions), std=0.01)\n",
    "        self.critic = self._layer_init(nn.Linear(512, 1))\n",
    "\n",
    "    def _layer_init(self, layer, std=np.sqrt(2), bias_const=0.0):\n",
    "        torch.nn.init.orthogonal_(layer.weight, std)\n",
    "        torch.nn.init.constant_(layer.bias, bias_const)\n",
    "        return layer\n",
    "\n",
    "    def get_value(self, x):\n",
    "        return self.critic(self.network(x / 255.0))\n",
    "\n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        hidden = self.network(x / 255.0)\n",
    "        logits = self.actor(hidden)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        return action, probs.log_prob(action), probs.entropy(), self.critic(hidden)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T20:41:40.590550Z",
     "start_time": "2024-06-09T20:41:40.584738Z"
    }
   },
   "id": "8b8eaf0d2843995f",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementacja procesu uczenia i ewaluacji polityki"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a2bd0247cc618fa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class PPOLearner:\n",
    "    def __init__(self, agent_class, env, params: AlgoParams):\n",
    "        self.losses = []\n",
    "        self.policy_losses = []\n",
    "        self.params = params\n",
    "        self.env = env\n",
    "        self.agent = agent_class(env.action_space(env.possible_agents[0]).n).to(params.device)\n",
    "        self.optimizer = optim.Adam(self.agent.parameters(), lr=0.001, eps=1e-5)\n",
    "\n",
    "        self.num_agents = len(env.possible_agents)\n",
    "        self.observation_size = env.observation_space(env.possible_agents[0]).shape\n",
    "\n",
    "        self.rb_obs = torch.zeros(\n",
    "            (params.max_cycles, self.num_agents, params.stack_size, *params.frame_size)\n",
    "        ).to(params.device)\n",
    "        tensor_dims = (params.max_cycles, self.num_agents)\n",
    "        self.rb_actions = torch.zeros(tensor_dims).to(params.device)\n",
    "        self.rb_logprobs = torch.zeros(tensor_dims).to(params.device)\n",
    "        self.rb_rewards = torch.zeros(tensor_dims).to(params.device)\n",
    "        self.rb_terms = torch.zeros(tensor_dims).to(params.device)\n",
    "        self.rb_values = torch.zeros(tensor_dims).to(params.device)\n",
    "\n",
    "    def train(self):\n",
    "        for episode in range(self.params.total_episodes):\n",
    "            with torch.no_grad():\n",
    "                next_obs, info = self.env.reset(seed=None)\n",
    "                total_episodic_return = 0\n",
    "                end_step = 0\n",
    "\n",
    "                for step in range(0, self.params.max_cycles):\n",
    "                    obs = self.batchify_obs(next_obs, self.params.device)\n",
    "                    actions, logprobs, _, values = self.agent.get_action_and_value(obs)\n",
    "                    next_obs, rewards, terms, truncs, infos = self.env.step(\n",
    "                        self.unbatchify(actions, self.env)\n",
    "                    )\n",
    "\n",
    "                    self.rb_obs[step] = obs\n",
    "                    self.rb_rewards[step] = self.batchify(rewards, self.params.device)\n",
    "                    self.rb_terms[step] = self.batchify(terms, self.params.device)\n",
    "                    self.rb_actions[step] = actions\n",
    "                    self.rb_logprobs[step] = logprobs\n",
    "                    self.rb_values[step] = values.flatten()\n",
    "                    total_episodic_return += self.rb_rewards[step].cpu().numpy()\n",
    "\n",
    "                    if any([terms[a] for a in terms]) or any([truncs[a] for a in truncs]):\n",
    "                        end_step = step\n",
    "                        break\n",
    "\n",
    "            with torch.no_grad():\n",
    "                rb_advantages = torch.zeros_like(self.rb_rewards).to(self.params.device)\n",
    "                for t in reversed(range(end_step)):\n",
    "                    delta = (\n",
    "                            self.rb_rewards[t]\n",
    "                            + self.params.gamma * self.rb_values[t + 1] * self.rb_terms[t + 1]\n",
    "                            - self.rb_values[t]\n",
    "                    )\n",
    "                    rb_advantages[t] = delta + self.params.gamma * self.params.gamma * rb_advantages[t + 1]\n",
    "                rb_returns = rb_advantages + self.rb_values\n",
    "\n",
    "            # convert our episodes to batch of individual transitions\n",
    "            b_obs = torch.flatten(self.rb_obs[:end_step], start_dim=0, end_dim=1)\n",
    "            b_logprobs = torch.flatten(self.rb_logprobs[:end_step], start_dim=0, end_dim=1)\n",
    "            b_actions = torch.flatten(self.rb_actions[:end_step], start_dim=0, end_dim=1)\n",
    "            b_returns = torch.flatten(rb_returns[:end_step], start_dim=0, end_dim=1)\n",
    "            b_values = torch.flatten(self.rb_values[:end_step], start_dim=0, end_dim=1)\n",
    "            b_advantages = torch.flatten(rb_advantages[:end_step], start_dim=0, end_dim=1)\n",
    "\n",
    "            b_index = np.arange(len(b_obs))\n",
    "            clip_fracs = []\n",
    "            for repeat in range(3):\n",
    "                np.random.shuffle(b_index)\n",
    "                for start in range(0, len(b_obs), self.params.batch_size):\n",
    "                    end = start + self.params.batch_size\n",
    "                    batch_index = b_index[start:end]\n",
    "\n",
    "                    _, newlogprob, entropy, value = self.agent.get_action_and_value(\n",
    "                        b_obs[batch_index], b_actions.long()[batch_index]\n",
    "                    )\n",
    "                    logratio = newlogprob - b_logprobs[batch_index]\n",
    "                    ratio = logratio.exp()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        old_approx_kl = (-logratio).mean()\n",
    "                        approx_kl = ((ratio - 1) - logratio).mean()\n",
    "                        clip_fracs.append(((ratio - 1.0).abs() > self.params.clip_coef).float().mean().item())\n",
    "\n",
    "                    advantages = b_advantages[batch_index]\n",
    "                    b_advantages[batch_index] = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "\n",
    "                    pg_loss1 = -b_advantages[batch_index] * ratio\n",
    "                    pg_loss2 = -b_advantages[batch_index] \\\n",
    "                        * torch.clamp(ratio, 1 - self.params.clip_coef, 1 + self.params.clip_coef)\n",
    "                    pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
    "\n",
    "                    value = value.flatten()\n",
    "                    v_loss_unclipped = (value - b_returns[batch_index]) ** 2\n",
    "                    v_clipped = b_values[batch_index] + torch.clamp(\n",
    "                        value - b_values[batch_index], -self.params.clip_coef, self.params.clip_coef,\n",
    "                    )\n",
    "                    v_loss_clipped = (v_clipped - b_returns[batch_index]) ** 2\n",
    "                    v_loss_max = torch.max(v_loss_unclipped, v_loss_clipped)\n",
    "                    v_loss = 0.5 * v_loss_max.mean()\n",
    "\n",
    "                    entropy_loss = entropy.mean()\n",
    "                    loss = pg_loss - self.params.ent_coef * entropy_loss + v_loss * self.params.vf_coef\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "            y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n",
    "            var_y = np.var(y_true)\n",
    "            explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n",
    "\n",
    "            self.losses.append(v_loss.item())\n",
    "            self.policy_losses.append(pg_loss.item())\n",
    "\n",
    "            self.visualize_step(\n",
    "                episode,\n",
    "                total_episodic_return,\n",
    "                end_step,\n",
    "                v_loss,\n",
    "                pg_loss,\n",
    "                old_approx_kl,\n",
    "                approx_kl,\n",
    "                clip_fracs,\n",
    "                explained_var\n",
    "            )\n",
    "\n",
    "    def batchify_obs(self, obs, device):\n",
    "        obs = np.stack([obs[a] for a in obs], axis=0)\n",
    "        obs = obs.transpose(0, -1, 1, 2)\n",
    "        obs = torch.tensor(obs).to(device)\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def batchify(self, x, device):\n",
    "        x = np.stack([x[a] for a in x], axis=0)\n",
    "        x = torch.tensor(x).to(device)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def unbatchify(self, x, env):\n",
    "        x = x.cpu().numpy()\n",
    "        x = {a: x[i] for i, a in enumerate(env.possible_agents)}\n",
    "\n",
    "        return x\n",
    "\n",
    "    def visualize_step(\n",
    "            self,\n",
    "            episode,\n",
    "            total_episodic_return,\n",
    "            end_step,\n",
    "            v_loss,\n",
    "            pg_loss,\n",
    "            old_approx_kl,\n",
    "            approx_kl,\n",
    "            clip_fracs,\n",
    "            explained_var\n",
    "    ) -> None:\n",
    "        print(f\"Training episode {episode}\")\n",
    "        print(f\"Episodic Return: {np.mean(total_episodic_return)}\")\n",
    "        print(f\"Episode Length: {end_step}\")\n",
    "        print(\"\")\n",
    "        print(f\"Value Loss: {v_loss.item()}\")\n",
    "        print(f\"Policy Loss: {pg_loss.item()}\")\n",
    "        print(f\"Old Approx KL: {old_approx_kl.item()}\")\n",
    "        print(f\"Approx KL: {approx_kl.item()}\")\n",
    "        print(f\"Clip Fraction: {np.mean(clip_fracs)}\")\n",
    "        print(f\"Explained Variance: {explained_var.item()}\")\n",
    "        print(\"\\n-------------------------------------------\\n\")\n",
    "\n",
    "    def render_policy(self, env):\n",
    "        self.agent.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # render 5 episodes out\n",
    "            for episode in range(5):\n",
    "                obs, infos = env.reset(seed=None)\n",
    "                obs = self.batchify_obs(obs, self.params.device)\n",
    "                terms = [False]\n",
    "                truncs = [False]\n",
    "                while not any(terms) and not any(truncs):\n",
    "                    actions, logprobs, _, values = self.agent.get_action_and_value(obs)\n",
    "                    obs, rewards, terms, truncs, infos = env.step(self.unbatchify(actions, env))\n",
    "                    obs = self.batchify_obs(obs, self.params.device)\n",
    "                    terms = [terms[a] for a in terms]\n",
    "                    truncs = [truncs[a] for a in truncs]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T20:41:43.580983Z",
     "start_time": "2024-06-09T20:41:43.564596Z"
    }
   },
   "id": "84b86138ced22694",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Proces uczenia"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86c6a510aa2da256"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "params = AlgoParams(max_cycles=1000, total_episodes=50, ent_coef=0.01, vf_coef=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T19:34:33.906033Z",
     "start_time": "2024-06-09T19:34:33.902831Z"
    }
   },
   "id": "be720692fae2fa77",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_env = flag_capture_v2.parallel_env(render_mode=\"rgb_array\", max_cycles=params.max_cycles)\n",
    "train_env = color_reduction_v0(train_env)\n",
    "train_env = resize_v1(train_env, *params.frame_size)\n",
    "train_env = frame_stack_v1(train_env, stack_size=params.stack_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T19:34:34.032483Z",
     "start_time": "2024-06-09T19:34:33.907477Z"
    }
   },
   "id": "9e9f5c56c6ffdada",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training episode 0\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 363.03338623046875\n",
      "Policy Loss: 0.0053311982192099094\n",
      "Old Approx KL: -0.02066000923514366\n",
      "Approx KL: 0.0029394328594207764\n",
      "Clip Fraction: 0.6654856387900296\n",
      "Explained Variance: -0.0004976987838745117\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 1\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 45168.44140625\n",
      "Policy Loss: 0.016535155475139618\n",
      "Old Approx KL: 0.01887243054807186\n",
      "Approx KL: 0.002828951459378004\n",
      "Clip Fraction: 0.21801776281267246\n",
      "Explained Variance: -0.00019276142120361328\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 2\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 440.6608581542969\n",
      "Policy Loss: 0.013443036004900932\n",
      "Old Approx KL: -0.006924203597009182\n",
      "Approx KL: 0.0005110119236633182\n",
      "Clip Fraction: 0.050595238095238096\n",
      "Explained Variance: -0.00037229061126708984\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 3\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 0.8280569911003113\n",
      "Policy Loss: 0.021792197600007057\n",
      "Old Approx KL: -0.011057530529797077\n",
      "Approx KL: 0.002524371724575758\n",
      "Clip Fraction: 0.09386810289804266\n",
      "Explained Variance: -0.032431721687316895\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 4\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 10.922402381896973\n",
      "Policy Loss: 0.001382783055305481\n",
      "Old Approx KL: -0.0010521752992644906\n",
      "Approx KL: 0.003671522717922926\n",
      "Clip Fraction: 0.05151643994308654\n",
      "Explained Variance: -0.0005385875701904297\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 5\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 26.90534019470215\n",
      "Policy Loss: -0.011396782472729683\n",
      "Old Approx KL: -0.0083830701187253\n",
      "Approx KL: 0.002085630316287279\n",
      "Clip Fraction: 0.08756141348806008\n",
      "Explained Variance: -0.004233360290527344\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 6\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 45.500938415527344\n",
      "Policy Loss: -0.0061262911185622215\n",
      "Old Approx KL: -0.0029411485884338617\n",
      "Approx KL: 0.001137954881414771\n",
      "Clip Fraction: 0.04728835978835979\n",
      "Explained Variance: -7.557868957519531e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 7\n",
      "Episodic Return: 0.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 37.68781280517578\n",
      "Policy Loss: -0.0061604976654052734\n",
      "Old Approx KL: 0.02076261304318905\n",
      "Approx KL: 0.002359926700592041\n",
      "Clip Fraction: 0.05064247923080253\n",
      "Explained Variance: -0.0008289813995361328\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 8\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 1.7785007953643799\n",
      "Policy Loss: 0.00815589725971222\n",
      "Old Approx KL: -0.004402279853820801\n",
      "Approx KL: 0.0017187425401061773\n",
      "Clip Fraction: 0.03902116402116402\n",
      "Explained Variance: -0.005656123161315918\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 9\n",
      "Episodic Return: 5.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 28.050294876098633\n",
      "Policy Loss: -2.090845737257041e-05\n",
      "Old Approx KL: 0.0058348518796265125\n",
      "Approx KL: 0.0008461730903945863\n",
      "Clip Fraction: 0.008928571428571428\n",
      "Explained Variance: -0.0007845163345336914\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 10\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 1.4722141027450562\n",
      "Policy Loss: -0.0025683811400085688\n",
      "Old Approx KL: 0.0014468772569671273\n",
      "Approx KL: 0.00025208081933669746\n",
      "Clip Fraction: 0.0013227513227513227\n",
      "Explained Variance: -0.0015610456466674805\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 11\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 4.613687038421631\n",
      "Policy Loss: 0.0021664851810783148\n",
      "Old Approx KL: 0.006222792901098728\n",
      "Approx KL: 0.0002491218619979918\n",
      "Clip Fraction: 0.0011574074074074073\n",
      "Explained Variance: -0.002962350845336914\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 12\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 2.24373197555542\n",
      "Policy Loss: 0.011923604644834995\n",
      "Old Approx KL: 0.0026391574647277594\n",
      "Approx KL: 0.000325620174407959\n",
      "Clip Fraction: 0.0006613756613756613\n",
      "Explained Variance: -2.0265579223632812e-06\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 13\n",
      "Episodic Return: 3.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 3.18536376953125\n",
      "Policy Loss: -0.0044873058795928955\n",
      "Old Approx KL: 0.01566130854189396\n",
      "Approx KL: 0.0010725046740844846\n",
      "Clip Fraction: 0.0013227513227513227\n",
      "Explained Variance: -4.8279762268066406e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 14\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 8.33372974395752\n",
      "Policy Loss: -0.018196675926446915\n",
      "Old Approx KL: -0.000432321015978232\n",
      "Approx KL: 0.00047635179362259805\n",
      "Clip Fraction: 0.001488095238095238\n",
      "Explained Variance: -0.004154682159423828\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 15\n",
      "Episodic Return: 0.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 0.6153505444526672\n",
      "Policy Loss: -0.007069728337228298\n",
      "Old Approx KL: -0.0006162268691696227\n",
      "Approx KL: 0.0026467868592590094\n",
      "Clip Fraction: 0.030517762694409284\n",
      "Explained Variance: -0.0010787248611450195\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 16\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 56.189632415771484\n",
      "Policy Loss: -0.03411778807640076\n",
      "Old Approx KL: -0.01446235179901123\n",
      "Approx KL: 0.0023833555169403553\n",
      "Clip Fraction: 0.010723733949282813\n",
      "Explained Variance: -0.002488255500793457\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 17\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 8.667876243591309\n",
      "Policy Loss: -0.008223144337534904\n",
      "Old Approx KL: -0.02330155111849308\n",
      "Approx KL: 0.0018537640571594238\n",
      "Clip Fraction: 0.031746031746031744\n",
      "Explained Variance: -6.961822509765625e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 18\n",
      "Episodic Return: 0.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 10.295441627502441\n",
      "Policy Loss: 0.005791455507278442\n",
      "Old Approx KL: -0.008192675188183784\n",
      "Approx KL: 0.0010568840662017465\n",
      "Clip Fraction: 0.02595899470899471\n",
      "Explained Variance: -0.0003610849380493164\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 19\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 9.945487022399902\n",
      "Policy Loss: -0.009126936085522175\n",
      "Old Approx KL: -0.008674876764416695\n",
      "Approx KL: 0.0021142533514648676\n",
      "Clip Fraction: 0.028746220721769584\n",
      "Explained Variance: -0.003161787986755371\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 20\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 14.35766315460205\n",
      "Policy Loss: -0.012734419666230679\n",
      "Old Approx KL: 0.021348271518945694\n",
      "Approx KL: 0.0010653691133484244\n",
      "Clip Fraction: 0.03356481481481482\n",
      "Explained Variance: -0.004154562950134277\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 21\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 4.335803031921387\n",
      "Policy Loss: -0.013464757241308689\n",
      "Old Approx KL: -0.04532388225197792\n",
      "Approx KL: 0.006730684079229832\n",
      "Clip Fraction: 0.005338246426569722\n",
      "Explained Variance: -0.20440959930419922\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 22\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 16.47413444519043\n",
      "Policy Loss: -0.015478323213756084\n",
      "Old Approx KL: -0.016825368627905846\n",
      "Approx KL: 0.0018275210168212652\n",
      "Clip Fraction: 0.07936507940450042\n",
      "Explained Variance: -0.004893660545349121\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 23\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 10.237521171569824\n",
      "Policy Loss: -0.017380017787218094\n",
      "Old Approx KL: 0.006002545356750488\n",
      "Approx KL: 0.0008193339454010129\n",
      "Clip Fraction: 0.0006613756613756613\n",
      "Explained Variance: -0.0002779960632324219\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 24\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 1.822710633277893\n",
      "Policy Loss: -0.003032488515600562\n",
      "Old Approx KL: -0.005760039668530226\n",
      "Approx KL: 0.0007650852203369141\n",
      "Clip Fraction: 0.0008267195767195767\n",
      "Explained Variance: -0.02029561996459961\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 25\n",
      "Episodic Return: 0.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 7.53912353515625\n",
      "Policy Loss: -0.021887393668293953\n",
      "Old Approx KL: 0.015404616482555866\n",
      "Approx KL: 0.0025990265421569347\n",
      "Clip Fraction: 0.14673091467253116\n",
      "Explained Variance: -0.0007737874984741211\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 26\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 78.44835662841797\n",
      "Policy Loss: 0.01147580984979868\n",
      "Old Approx KL: -0.005925399716943502\n",
      "Approx KL: 0.001417849794961512\n",
      "Clip Fraction: 0.12634637194966514\n",
      "Explained Variance: 3.7670135498046875e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 27\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 0.08872085064649582\n",
      "Policy Loss: 0.017938490957021713\n",
      "Old Approx KL: -0.008732318878173828\n",
      "Approx KL: 0.0021718016359955072\n",
      "Clip Fraction: 0.06613756613756613\n",
      "Explained Variance: 6.222724914550781e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 28\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 17.966175079345703\n",
      "Policy Loss: -0.0185005571693182\n",
      "Old Approx KL: 0.0174177885055542\n",
      "Approx KL: 0.0021318283397704363\n",
      "Clip Fraction: 0.07735733187230176\n",
      "Explained Variance: -4.6372413635253906e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 29\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 0.4653659462928772\n",
      "Policy Loss: -0.00725599704310298\n",
      "Old Approx KL: -0.010956423357129097\n",
      "Approx KL: 0.0015161378541961312\n",
      "Clip Fraction: 0.01766817839372726\n",
      "Explained Variance: -0.0008909702301025391\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 30\n",
      "Episodic Return: 0.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 27.61981201171875\n",
      "Policy Loss: -0.0037029299419373274\n",
      "Old Approx KL: -0.015383652411401272\n",
      "Approx KL: 0.00025570817524567246\n",
      "Clip Fraction: 0.0006613756613756613\n",
      "Explained Variance: 4.887580871582031e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 31\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 0.1605665236711502\n",
      "Policy Loss: -0.00989961065351963\n",
      "Old Approx KL: 0.013792923651635647\n",
      "Approx KL: 0.0014202637830749154\n",
      "Clip Fraction: 0.01455026455026455\n",
      "Explained Variance: -0.0012736320495605469\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 32\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 12.782179832458496\n",
      "Policy Loss: -0.01368662714958191\n",
      "Old Approx KL: 0.01980992779135704\n",
      "Approx KL: 0.0006627994007430971\n",
      "Clip Fraction: 0.00016534391534391533\n",
      "Explained Variance: -0.00015652179718017578\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 33\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 3.905839443206787\n",
      "Policy Loss: -0.0024912867229431868\n",
      "Old Approx KL: -0.007484691683202982\n",
      "Approx KL: 0.0006337974919006228\n",
      "Clip Fraction: 0.0006613756613756613\n",
      "Explained Variance: -3.0159950256347656e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 34\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 5.271016597747803\n",
      "Policy Loss: 0.008696837350726128\n",
      "Old Approx KL: -0.006314720492810011\n",
      "Approx KL: 0.00019031763076782227\n",
      "Clip Fraction: 0.0006613756613756613\n",
      "Explained Variance: -0.0009139776229858398\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 35\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 4.9202046394348145\n",
      "Policy Loss: 0.023272434249520302\n",
      "Old Approx KL: -0.00301969051361084\n",
      "Approx KL: 0.001383751630783081\n",
      "Clip Fraction: 0.07490079365079365\n",
      "Explained Variance: 0.00026232004165649414\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 36\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 4.6438984870910645\n",
      "Policy Loss: 0.0013138906797394156\n",
      "Old Approx KL: 0.0005706548690795898\n",
      "Approx KL: 0.001257168361917138\n",
      "Clip Fraction: 0.001488095238095238\n",
      "Explained Variance: -0.010652542114257812\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 37\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 4.88779354095459\n",
      "Policy Loss: -0.005062476731836796\n",
      "Old Approx KL: -0.007378782611340284\n",
      "Approx KL: 0.0007816978613846004\n",
      "Clip Fraction: 0.11507936507936507\n",
      "Explained Variance: 0.00011134147644042969\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 38\n",
      "Episodic Return: 0.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 4.627665996551514\n",
      "Policy Loss: -0.005118208471685648\n",
      "Old Approx KL: -0.009251066483557224\n",
      "Approx KL: 0.0005366929690353572\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: -0.0005536079406738281\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 39\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 4.7632832527160645\n",
      "Policy Loss: 0.005267273169010878\n",
      "Old Approx KL: 0.020217878744006157\n",
      "Approx KL: 0.0008775080787017941\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: 4.2557716369628906e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 40\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 3.604166030883789\n",
      "Policy Loss: 0.0061410581693053246\n",
      "Old Approx KL: -0.0033607142977416515\n",
      "Approx KL: 0.00030542697641067207\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: -7.62939453125e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 41\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 4.226137161254883\n",
      "Policy Loss: 0.0016624501440674067\n",
      "Old Approx KL: 0.001257675001397729\n",
      "Approx KL: 0.0003513438277877867\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: 2.288818359375e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 42\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 3.7325761318206787\n",
      "Policy Loss: 0.0005824012332595885\n",
      "Old Approx KL: -0.003909843508154154\n",
      "Approx KL: 0.00025976556935347617\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: -3.993511199951172e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 43\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 4.9940619468688965\n",
      "Policy Loss: -0.006025312002748251\n",
      "Old Approx KL: 0.00445766095072031\n",
      "Approx KL: 0.00015476772387046367\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: 1.0132789611816406e-06\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 44\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 2.6539406776428223\n",
      "Policy Loss: -0.0023667344357818365\n",
      "Old Approx KL: -0.007533601485192776\n",
      "Approx KL: 0.00040848340722732246\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: -8.96453857421875e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 45\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 3.5726253986358643\n",
      "Policy Loss: -0.0013799710432067513\n",
      "Old Approx KL: 0.005524533335119486\n",
      "Approx KL: 0.00043078832095488906\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: 1.2218952178955078e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 46\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 3.892817974090576\n",
      "Policy Loss: -0.007784304674714804\n",
      "Old Approx KL: -0.007607630454003811\n",
      "Approx KL: 0.0003516972064971924\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: -2.3126602172851562e-05\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 47\n",
      "Episodic Return: 0.0\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 3.818507432937622\n",
      "Policy Loss: -0.0032079655211418867\n",
      "Old Approx KL: -0.0012762887636199594\n",
      "Approx KL: 0.0001235050876857713\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: 2.9802322387695312e-06\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 48\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 3.4331204891204834\n",
      "Policy Loss: 0.0002759865310508758\n",
      "Old Approx KL: -0.0021145003847777843\n",
      "Approx KL: 0.0002887845039367676\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: -7.510185241699219e-06\n",
      "\n",
      "-------------------------------------------\n",
      "Training episode 49\n",
      "Episodic Return: 2.5\n",
      "Episode Length: 999\n",
      "\n",
      "Value Loss: 3.428025722503662\n",
      "Policy Loss: 0.003207436529919505\n",
      "Old Approx KL: 0.0027576854918152094\n",
      "Approx KL: 0.00017446705896873027\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: 0.0\n",
      "\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ppo_learner = PPOLearner(Agent, train_env, params)\n",
    "ppo_learner.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T19:52:12.811732Z",
     "start_time": "2024-06-09T19:34:34.033161Z"
    }
   },
   "id": "e50fdfe2fb5924d4",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Krzywa uczenia na podstawie _policy loss_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49d70feca2cd8fa0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x3462c7010>]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ppo_learner.policy_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T20:09:31.594653Z",
     "start_time": "2024-06-09T20:09:31.536579Z"
    }
   },
   "id": "f2aa96400377af48",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Proces ewaluacji i wyświetlenia wyników uczenia w postaci gry"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11f69dd03a1264aa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m env \u001B[38;5;241m=\u001B[39m resize_v1(env, \u001B[38;5;241m*\u001B[39mparams\u001B[38;5;241m.\u001B[39mframe_size)\n\u001B[1;32m      4\u001B[0m env \u001B[38;5;241m=\u001B[39m frame_stack_v1(env, stack_size\u001B[38;5;241m=\u001B[39mparams\u001B[38;5;241m.\u001B[39mstack_size)\n\u001B[0;32m----> 6\u001B[0m ppo_learner\u001B[38;5;241m.\u001B[39mrender_policy(env)\n",
      "File \u001B[0;32m~/SemestrVI/computational-intelligence-in-digital-data-analysis/lab6/main.py:214\u001B[0m, in \u001B[0;36mPPOLearner.render_policy\u001B[0;34m(self, env)\u001B[0m\n\u001B[1;32m    212\u001B[0m truncs \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mFalse\u001B[39;00m]\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28many\u001B[39m(terms) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28many\u001B[39m(truncs):\n\u001B[0;32m--> 214\u001B[0m     actions, logprobs, _, values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39magent\u001B[38;5;241m.\u001B[39mget_action_and_value(obs)\n\u001B[1;32m    215\u001B[0m     obs, rewards, terms, truncs, infos \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munbatchify(actions, env))\n\u001B[1;32m    216\u001B[0m     obs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatchify_obs(obs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[0;32m~/SemestrVI/computational-intelligence-in-digital-data-analysis/lab6/Agent.py:45\u001B[0m, in \u001B[0;36mAgent.get_action_and_value\u001B[0;34m(self, x, action)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_action_and_value\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, action\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 45\u001B[0m     hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnetwork(x \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255.0\u001B[39m)\n\u001B[1;32m     46\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactor(hidden)\n\u001B[1;32m     47\u001B[0m     probs \u001B[38;5;241m=\u001B[39m Categorical(logits\u001B[38;5;241m=\u001B[39mlogits)\n",
      "File \u001B[0;32m~/anaconda3/envs/CI-in-DDA/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/CI-in-DDA/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/CI-in-DDA/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/CI-in-DDA/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/CI-in-DDA/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/CI-in-DDA/lib/python3.11/site-packages/torch/nn/modules/pooling.py:164\u001B[0m, in \u001B[0;36mMaxPool2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor):\n\u001B[0;32m--> 164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mmax_pool2d(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    165\u001B[0m                         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, ceil_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mceil_mode,\n\u001B[1;32m    166\u001B[0m                         return_indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_indices)\n",
      "File \u001B[0;32m~/anaconda3/envs/CI-in-DDA/lib/python3.11/site-packages/torch/_jit_internal.py:497\u001B[0m, in \u001B[0;36mboolean_dispatch.<locals>.fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    495\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m if_true(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 497\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m if_false(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/CI-in-DDA/lib/python3.11/site-packages/torch/nn/functional.py:796\u001B[0m, in \u001B[0;36m_max_pool2d\u001B[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001B[0m\n\u001B[1;32m    794\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stride \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    795\u001B[0m     stride \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mannotate(List[\u001B[38;5;28mint\u001B[39m], [])\n\u001B[0;32m--> 796\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mmax_pool2d(\u001B[38;5;28minput\u001B[39m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "env = flag_capture_v2.parallel_env(render_mode=\"human\")\n",
    "env = color_reduction_v0(env)\n",
    "env = resize_v1(env, *params.frame_size)\n",
    "env = frame_stack_v1(env, stack_size=params.stack_size)\n",
    "\n",
    "ppo_learner.render_policy(env)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T20:08:16.287205Z",
     "start_time": "2024-06-09T20:04:48.227048Z"
    }
   },
   "id": "1cf596d917b96807",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
